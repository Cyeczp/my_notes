# 第五章 系统评估与优化

**大模型评估方法**

​		找到bad cases ===>优化prompt或检索架构。

​		每次优化后，都需将验证集中的所有验证案例进行验证，以防good cases降级。

**人工评估**

​		1.量化评估：每一个验证案例的回答都给出打分，最后计算所有验证案例的平均分得到本版本系统的得分。

​		2.多维评估：设计多个维度来进行评估。

​		3.简单自动评估：构造客观题、计算答案相似度等。

**使用大模型进行评估**

​		通过构造 Prompt Engineering 让大模型充当一个评估者的角色，采用多维度量化评估的方式，实现快速全面的评估。

**混合评估**

​		上述评估方法都不是孤立、对立的，可以将多种评估方法混合起来，选取合适的评估方法。



### **评估并优化生成部分**

**评估生成部分性能**

1. **构建验证集:** 针对性构造验证集，从多个维度对系统性能进行评估。
2. **分析 Bad Case:** 结合评估结果，对评估出的 Bad Case 进行拆分，并分别对每一部分做出评估和优化。

**优化生成部分**

1. **优化 Prompt Engineering:** 由于大模型基座已限定，可以通过优化 Prompt Engineering 来优化生成的回答。



### 评估并优化检索部分

​		1.评估检索效果

​		2.优化检索的思路：知识片段合理切割、优化知识库构建方式、关键词优化及优化向量模型或是构建倒排索引。





​		
