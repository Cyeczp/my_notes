# 第一章 大语言模型简介



## 什么是大语言模型

​		大语言模型（Large Language Model, LLM）是特指在自然语言处理（NLP）领域，具有大量参数并通过大规模文本数据训练的深度学习模型。这些模型能够理解和生成自然语言文本，广泛应用于各种语言处理任务。

## LLM 的能力与特点

- ### 涌现能力

**上下文学习**：这种能力允许语言模型在提供自然语言指令或多个任务示例的情况下，通过理解上下文并生成相应输出的方式来执行任务，而无需额外的训练或参数更新。

**指令遵循**：即指令微调，LLM 被证明在使用指令形式化描述的未见过的任务上表现良好，所以LLM 能够根据任务指令执行任务，而无需事先见过具体示例，展示了其强大的泛化能力。

**逐步推理**：LLM 通过采用 思维链（CoT, Chain of Thought） 推理策略，利用包含中间推理步骤的提示机制来解决这些任务，从而得出最终答案。

- ### 作为基座模型支持多元应用的能力

​	多个应用可以只依赖于一个或少数几个大模型进行统一建设。

​		`基座模型解释：基座模型（Foundation Model）是指在人工智能和机器学习领域中，预训练在大规模数据集上的通用模型，这些模型具备强大的泛化能力和灵活性，能够在多种任务和领域中发挥作用。基座模型的核心特点是它们在预训练阶段学习到了广泛的知识和语言模式，之后可以通过微调（如指令微调）适应特定任务，从而显著提升各类下游任务的性能。`

- ### 支持对话作为统一入口的能力

## LLM特点

- ​	**巨大的规模：**参数规模巨大。
- ​	**预训练和微调：**首先在大规模文本数据上进行预训练（无标签数据），然后通过微调（有标签数据）适应特定任务。
- ​	**上下文感知：**能够理解和生成依赖于前文的文本内容。
- ​	**多语言支持：** LLM 可以用于多种语言。
- ​	**多模态支持：**支持多模态数据，包括文本、图像和声音。
- ​	**伦理和风险问题：**引发伦理和风险问题。
- ​	**高计算资源需求：**需要大量的计算资源进行训练和推理。



## **检索增强生成（RAG, Retrieval-Augmented Generation）**

## 什么是 RAG

RAG 是一种将检索（Retrieval）和生成（Generation）结合起来的方法，通常用于改进文本生成任务。

RAG 模型主要包含以下两个部分：

1. **检索模块（Retriever）**：这个模块负责从一个大的知识库（例如，文档集、知识图谱、数据库等）中检索相关信息。检索模块通常基于信息检索技术，例如 TF-IDF、BM25 或者基于深度学习的检索模型（例如，基于 BERT 的双编码器模型）。
2. **生成模块（Generator）**：这个模块接收检索模块返回的相关信息，并利用这些信息来生成最终的输出文本。生成模块通常是一个预训练的语言模型（例如，GPT-3、T5 等），它可以根据输入的上下文和检索到的信息生成连贯和相关的文本。

RAG 模型的工作流程通常如下：

- 给定一个输入查询，检索模块首先从知识库中找到与查询相关的文档或信息片段。
- 生成模块然后基于输入查询和检索到的信息，生成最终的回答或文本。

通过这种方式，RAG 模型能够结合外部知识库的信息生成更加准确和丰富的文本回答。这种方法特别适用于需要利用外部知识来回答问题的任务，例如开放域问答、对话系统、信息生成等。

### LLM 面临的主要问题

- **信息偏差/幻觉：** LLM 有时会产生与客观事实不符的信息。
- **知识更新滞后性：** LLM 基于静态的数据集训练，这可能导致模型的知识更新滞后，无法及时反映最新的信息动态。
- **内容不可追溯：** LLM 生成的内容往往缺乏明确的信息来源，影响内容的可信度。
- **领域专业知识能力欠缺：** LLM 在处理特定领域的专业知识时，效果可能不太理想，从而影响回答质量。
- **推理能力限制：** 面对复杂问题时，LLM 可能缺乏必要的推理能力，这影响了其对问题的理解和回答。
- **应用场景适应性受限：** LLM 需在多样化的应用场景中保持高效和准确，但单一模型可能难以全面适应所有场景。
- **长文本处理能力较弱：** LLM 在理解和生成长篇内容时受限于有限的上下文窗口，且必须按顺序处理内容，输入越长，速度越慢。

## RAG工作流程

RAG 是⼀个完整的系统，其⼯作流程可以简单地分为数据处理、检索、增强和⽣成四个阶段。

1. 数据处理阶段

   ​        i. 对原始数据进⾏清洗和处理。

   ​        ii. 将处理后的数据转化为检索模型可以使⽤的格式。

   ​        iii. 将处理后的数据存储在对应的数据库中。

2. 检索阶段

   ​        i. 将⽤户的问题输⼊到检索系统中，从数据库中检索相关信息。

3. 增强阶段

   ​        i. 对检索到的信息进⾏处理和增强，以便⽣成模型可以更好地理解和使⽤。

4. ⽣成阶段

   ​        i. 将增强后的信息输⼊到⽣成模型中，⽣成模型根据这些信息⽣成答案。

![检索增强生成（RAG）的工作流程：从用户查询开始，通过向量数据库检索，到填充提示，最终形成回答的全过程。](https://baoyu.io/images/rag/retrieval-augmented-generation-rag-from-theory-to-langchain-implementation/1_kSkeaXRvRzbJ9SrFZaMoOg.webp)

### RAG VS Finetune

| 特征比较 | RAG                                                          | 微调                                                         |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 知识更新 | 直接更新检索知识库，无需重新训练。信息更新成本低，适合动态变化的数据。 | 通常需要重新训练来保持知识和数据的更新。更新成本高，适合静态数据。 |
| 外部知识 | 擅长利用外部资源，特别适合处理文档或其他结构化/非结构化数据库。 | 将外部知识学习到 LLM 内部。                                  |
| 数据处理 | 对数据的处理和操作要求极低。                                 | 依赖于构建高质量的数据集，有限的数据集可能无法显著提高性能。 |
| 模型定制 | 侧重于信息检索和融合外部知识，但可能无法充分定制模型行为或写作风格。 | 可以根据特定风格或术语调整 LLM 行为、写作风格或特定领域知识。 |
| 可解释性 | 可以追溯到具体的数据来源，有较好的可解释性和可追踪性。       | 黑盒子，可解释性相对较低。                                   |
| 计算资源 | 需要额外的资源来支持检索机制和数据库的维护。                 | 依赖高质量的训练数据集和微调目标，对计算资源的要求较高。     |
| 推理延迟 | 增加了检索步骤的耗时                                         | 单纯 LLM 生成的耗时                                          |
| 降低幻觉 | 通过检索到的真实信息生成回答，降低了产生幻觉的概率。         | 模型学习特定领域的数据有助于减少幻觉，但面对未见过的输入时仍可能出现幻觉。 |
| 伦理隐私 | 检索和使用外部数据可能引发伦理和隐私方面的问题。             | 训练数据中的敏感信息需要妥善处理，以防泄露。                 |

## LangChain

### 什么是LangChain

LangChain 是一个框架，用于构建可以与大型语言模型（LLMs）进行交互的应用程序。该框架特别关注以下几个核心领域：

1. **语言模型链**：将多个语言模型串联起来，形成一个复杂的管道，以处理更复杂的任务。
2. **数据增强生成**：通过集成外部数据源来增强生成结果的准确性和实用性。
3. **上下文管理**：管理和利用上下文信息，以提高语言模型的响应质量。

### LangChain 的核心组件

1. **链（Chains）**：
   - Chains 是 LangChain 的核心概念之一，指的是将多个语言模型或功能模块组合在一起，以形成复杂的处理管道。例如，可以将一个模型的输出作为另一个模型的输入，形成一个多步骤的处理流程。
2. **代理（Agents）**：
   - Agents 是能够根据用户输入动态调用不同功能模块或链的实体。它们可以根据任务的需要，灵活地选择和组合不同的处理步骤，从而实现更智能和灵活的响应。
3. **工具（Tools）**：
   - Tools 是特定的功能模块或服务，可以执行特定的任务。例如，可以是一个查询数据库的工具，一个调用外部 API 的工具，或者一个执行特定计算的工具。这些工具可以与语言模型结合使用，以增强其功能。
4. **记忆（Memory）**：
   - 记忆模块允许应用程序保存和检索上下文信息，以便在多个交互过程中保持状态和连续性。这对于对话系统或需要长期上下文跟踪的应用非常重要。

# 开发 LLM 应用的整体流程



![大模型开发流程](https://datawhalechina.github.io/llm-universe/figures/C1-4-LLM_developing_whole.png)

### 开发目标确定

1. 确定应用场景、目标人群、核心价值。
2. 设定最小化目标，构建 MVP（最小可行性产品）。

### 功能设计

1. 确定核心功能。
2. 设计核心功能的上下游功能。

### 搭建整体架构

1. 基于特定数据库 + Prompt + 通用大模型的架构。
2. 推荐使用 LangChain 框架进行开发。

### 搭建数据库

1. 使用向量数据库（如 Chroma）。
2. 收集数据并进行预处理。
3. 数据预处理包括格式转化和数据清洗。
4. 切片、向量化数据，构建个性化数据库。

### Prompt Engineering

1. 明确 Prompt 设计的一般原则及技巧。
2. 构建小型验证集。
3. 设计并迭代构建优质的 Prompt。

### 验证迭代

1. 进行实际业务测试，发现 Bad Case。
2. 分析问题并迭代优化 Prompt，提升系统效果。

### 前后端搭建

1. 搭建前后端，设计产品页面。
2. 使用 Gradio 和 Streamlit 快速搭建可视化页面，实现 Demo 上线。

### 体验优化

1. 上线应用，进行用户体验跟踪。
2. 记录 Bad Case 与用户反馈，进行针对性优化。













